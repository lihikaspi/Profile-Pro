{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18bfc611-a9d3-4544-b843-6315fb84906a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Profile Pro: A LinkedIn Profile Optimizer\n",
    "## Final Project - Data Collection Lab (0940290)\n",
    "### Lihi Kaspi (214676140), Harel Oved (326042389) & Lior Zaphir (326482213)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99768cc0-a0cb-41a7-adaa-80ef43645fee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "import pandas as pd\n",
    "from pyspark.ml.feature import CountVectorizer, Tokenizer, StringIndexer, VectorAssembler, Tokenizer, OneHotEncoder, Word2Vec, HashingTF, IndexToString\n",
    "from pyspark.ml.linalg import SparseVector, Vectors\n",
    "import numpy as np\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.window import Window\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b928cc60-2d1c-4e5f-b270-3d541c3a15c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Relevant Data and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ecf75da4-9ddb-47ca-80f5-b7a9a26e218d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## i'm moving all the code cells that create a parquet file to different notebooks so we don't have to skip cells when running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22138499-831b-4f17-ae92-f17233177be1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# original datasets\n",
    "companies = spark.read.parquet('/dbfs/linkedin_train_data')\n",
    "profiles = spark.read.parquet('/dbfs/linkedin_people_train_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4ef8341-14db-4057-a4e7-e223adc0b954",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# new df of profiled with their \"good profile\" score -- code can be found in \"Profile Score Calculation\"\n",
    "profiles_with_scores = spark.read.parquet(\"/Workspace/Users/lihi.kaspi@campus.technion.ac.il/user_profiles_with_scores.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2757fd63-0941-4d9f-9ea6-846ff83b48b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# new df with processed vector to go into the model\n",
    "processed_data = spark.read.parquet(\"/Workspace/Users/lihi.kaspi@campus.technion.ac.il/processed_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba01fdc3-1a17-4831-ae1c-ff781e1a8ed9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "311aaac7-9462-436b-9719-27e5d9d5a46f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## i moved this code to the \"Data_Preprocessing\" notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f9cfe18-ebae-4578-9e90-45d68171d5c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Scraped Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73d6a7f4-8d8a-4c86-8e82-5833f04a2305",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Job Titles and Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88d9f76c-c578-4b11-bc93-c04a000540c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "jobs = profiles.select('name', 'id', 'city', 'country_code', f.col('current_company').getField('name').alias('company_name'), f.col('experience')[0].getField('title').alias('job_title'), 'position')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecaad7f1-0949-4dba-bc42-a33b8f5bbb86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "jobs.display(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b1dde82-9c1c-4bb7-8869-46bd9e976297",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####Clustering job titles into meta job titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f03fd01-bb46-472d-b31e-781966de86c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lower, when, split\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml.feature import Word2Vec, Tokenizer\n",
    "\n",
    "# Create a DataFrame with the specified centroids\n",
    "centroids_data = [\n",
    "    ('Leadership',), ('Product',), ('Engineering',), ('DataScience',), ('Operations',),\n",
    "    ('Marketing',), ('Sales',), ('Design',), ('Support',), ('Finance',),\n",
    "    ('Resources',), ('Research',), ('Healthcare',), ('Education',), ('Security',),\n",
    "    ('Logistics',), ('Legal',), ('Quality',), ('Management',), ('Content',)\n",
    "]\n",
    "\n",
    "centroids_df = spark.createDataFrame(centroids_data, ['processed_title'])\n",
    "\n",
    "# Preprocess job titles\n",
    "job_titles_df = jobs.select(\n",
    "    when(col('job_title').isNotNull(), lower(col('job_title')))\n",
    "    .otherwise(lower(col('position')))\n",
    "    .alias('processed_title')\n",
    ")\n",
    "job_titles_df = job_titles_df.dropna()\n",
    "tokenizer = Tokenizer(inputCol=\"processed_title\", outputCol=\"tokened_title\")\n",
    "w2v = Word2Vec(inputCol=\"tokened_title\", outputCol=\"vector\", vectorSize=200, minCount=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build the pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, w2v])\n",
    "\n",
    "# Train the pipeline model\n",
    "model_vectorize = pipeline.fit(job_titles_df)\n",
    "\n",
    "\n",
    "\n",
    "# Create embeddings for job titles and centroids\n",
    "jobs_with_vectors = model_vectorize.transform(job_titles_df)\n",
    "centroids_with_vectors = model_vectorize.transform(centroids_df)\n",
    "\n",
    "\n",
    "jobs_temp = jobs_with_vectors.withColumnRenamed('vector', 'job_vector')\n",
    "jobs_temp = jobs_temp.withColumnRenamed('processed_title', 'job_title')\n",
    "\n",
    "centroids_temp = centroids_with_vectors.withColumnRenamed('processed_title', 'meta_job')\n",
    "centroids_temp = centroids_temp.withColumnRenamed('vector', 'centroid_vector')\n",
    "\n",
    "joined = jobs_temp.join(centroids_temp)\n",
    "display(joined.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09660b36-5c96-4000-8114-13a3e16c1734",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "import math\n",
    "\n",
    "# Define a function to calculate cosine similarity\n",
    "def cosine_similarity(v1, v2):\n",
    "    if v1 is None or v2 is None:\n",
    "        return None\n",
    "    dot_product = float(v1.dot(v2))  # Dot product of the two vectors\n",
    "    norm_v1 = math.sqrt(v1.dot(v1))  # Magnitude (norm) of v1\n",
    "    norm_v2 = math.sqrt(v2.dot(v2))  # Magnitude (norm) of v2\n",
    "    if norm_v1 == 0 or norm_v2 == 0:\n",
    "        return None  # Avoid division by zero\n",
    "    return dot_product / (norm_v1 * norm_v2)\n",
    "\n",
    "# Register the function as a UDF\n",
    "cosine_similarity_udf = udf(cosine_similarity, StringType())\n",
    "\n",
    "# Add a new column to compute cosine similarity\n",
    "joined = joined.withColumn(\n",
    "    \"cosine_similarity\",\n",
    "    cosine_similarity_udf(col(\"job_vector\"), col(\"centroid_vector\"))\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "joined.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "074e77d5-0325-4fab-8133-aaee42b0a084",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "window_spec = Window.partitionBy(\"job_title\").orderBy(col(\"cosine_similarity\").desc())\n",
    "\n",
    "# Rank centroids for each job and select the closest one\n",
    "ranked_df = joined.withColumn(\"rank\", f.row_number().over(window_spec))\n",
    "\n",
    "# Filter for the closest centroid\n",
    "closest_centroids = ranked_df.filter(col(\"rank\") == 1)\n",
    "\n",
    "# Select relevant columns\n",
    "result_df = closest_centroids.select(\n",
    "    col(\"job_title\"),\n",
    "    col(\"meta_job\").alias(\"closest_centroid\"),\n",
    "    col(\"cosine_similarity\")\n",
    ")\n",
    "\n",
    "# Display the result\n",
    "result_df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4419c0cc-1872-4b67-987d-4b524c095f44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "profiles_with_state = profiles.withColumn(\n",
    "    \"state\",\n",
    "    split(col(\"city\"), \", \")[1]  # The second element is the state\n",
    ")\n",
    "\n",
    "# Show the results\n",
    "states_df = profiles_with_state.select(\"state\").dropDuplicates().dropna()\n",
    "states_df.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36ec5e25-f521-4c0d-b2b0-3985d1ef22c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####Scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28ff6587-7102-4f22-a13a-a8c601153c5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install selenium\n",
    "%pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ccd16ea-b9c8-4d79-9df3-2f464f6a8e99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## this notebook is way to big so maybe move the scraping process to a new notebook and save the data in a parquet file to read from this notebook?\n",
    "Yes we should divide the parts to differnet files it will be good to display them separately in the git\n",
    "\n",
    "exactly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc4c94e6-1391-4176-bf49-22bcc41d3a8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "profiles_with_state = profiles.withColumn('state', split(col('city'), ', ')[1])\n",
    "profiles_with_count = profiles_with_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8afcc7df-668f-421a-8237-17a41fc72644",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Good Profiles Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e9975a2-2a9f-463d-bff2-61623935763d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### i want to predit a numeric score and not binary label -- will be better for the final stage of suggesting improvemnts\n",
    "### maybe predict categories of score (example below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71148ed7-d8e4-4a42-a657-626a6c78d63f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64dc7421-9343-4d12-a997-5913ff8f36a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "possible models:\n",
    "- Decision Tree Regressor\n",
    "- Random Forest Regressor\n",
    "- Gradient-Boosted Trees Regressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99be653a-17ec-4776-a9d1-2e0161bdc57b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3100db3c-4d73-4fab-bb62-e8f899d6d172",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e622f6df-80aa-47d0-a5fa-7518ffd81013",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c20c6171-2c93-4759-a167-ac92d564d0ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "when checking accuracy - accepted score should be between (real_score-5, real_score+5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef28b933-4f71-4731-a32f-6bf219267eaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Profile Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ab612f1-eee5-42ea-baed-78284e6c9683",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 'about' Section Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a83e58b4-215f-40fe-a79a-0989590d452e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# take: about (if not null), position, job title, reccomendations \n",
    "# --> return: a sentence or two describing the person and job (in a new column called 'new_about')\n",
    "# if all null: return message 'could not generate a short bio -- add more information to your profile' (put null in 'new_about' and add message in a new column called 'about_message')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0db48a2-457c-45be-9c59-118647dca859",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Improvements and Suggetions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bf77270-eb22-40f3-b9ea-1af23ad698a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "score ranking:\n",
    "- excellent score - 90+ and no suggestions\n",
    "- high score - 90+ and atleast one suggestion\n",
    "- medium high score - 60-90\n",
    "- medium score - 40-60\n",
    "- medium low score - 20-40\n",
    "- low score - 20>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "187a0312-7fa5-4b34-9bd9-af75a6f1d18c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "score_messages = {\n",
    "    'excellent score': 'Your profile is excellent, keep it up!',\n",
    "    'high score': 'Your profile is very strong, Check the suggestions to make it excellent',\n",
    "    'medium high score': 'Your profile is good, Try to follow the suggestions to make it even better',\n",
    "    'medium score': 'Your profile could use a few improvements, Try to follow the suggestions to make it even better',\n",
    "    'medium low score': 'Your profile needs to improve, Try to follow the suggestion to make it better',\n",
    "    'low score': 'Your profile is weak, Try to follow the suggestion to make it better',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15d4234a-8ae9-4b09-8fc8-a9eafb9a5681",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "missing_field_messages = {\n",
    "    'no_experience': 'Add previous/current comapnies you worked in', \n",
    "    'no_education': 'List your degrees and schools you graduated from',\n",
    "    'no_about': 'Add a short bio about yourself, here is a suggestion: ',\n",
    "    'suggested_about': 'Try out this about section: ',\n",
    "    'no_company': 'Add the company you currently work in',\n",
    "    'no_languages': 'List all the languages you know and the level of knowledge',\n",
    "    'no_position': 'Add the position you are currently in',\n",
    "    'no_posts': 'Try to be more active with you account',\n",
    "    'no_recommendations': 'Ask a colleague to write a few words about you',\n",
    "    'missing_experience': 'There is a gap in your resume, Don\\'t forget to add all of the previous comapnies you worked in',\n",
    "    'low_followers': 'Ask your colleagues and friends to follow you on LinkedIn!'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5321e47c-06aa-45f3-a950-fb0521d824e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# placeholder name for the predictions: predicted_df (has all the previous columns + score predictions)\n",
    "\n",
    "predicted_df = predicted_df.withColumn(\n",
    "  'score_rank', \n",
    "  f.when(f.col('score') < 20, 'low score'\n",
    "  ).when(f.col('score') < 40, 'medium low score'\n",
    "  ).when(f.col('score') < 60, 'medium score'\n",
    "  ).when(f.col('score') < 90, 'medium high score'\n",
    "  ).when(f.col('filled_percent') < 100, 'high score'\n",
    "  ).otherwise('excellent score')\n",
    ")\n",
    "\n",
    "predicted_df = predicted_df.withColumn(\n",
    "  'score_message',\n",
    "  score_messages.get(f.col('score_rank'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82696174-9da2-4377-9508-61ae90a1ce13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# find if there are gaps in the experience array (name new column: 'gap_in_experience')\n",
    "# TODO: Binary or explicit time period? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70f31f75-c24a-4033-83d0-67280a4a84f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predicted_df = predicted_df.withColumn('suggestions', f.array())\n",
    "\n",
    "predicted_df = predicted_df.withColumn(\n",
    "  'suggestions',\n",
    "  f.array(\n",
    "    f.when(\n",
    "      f.size(f.col('education')) == 0, \n",
    "      missing_field_messages.get('no_education')),\n",
    "    f.when(\n",
    "      f.size(f.col('current_company')) == 0, \n",
    "      missing_field_messages.get('no_company')),\n",
    "    f.when(\n",
    "      f.size(f.col('languages')) == 0, \n",
    "      missing_field_messages.get('no_languages')),\n",
    "    f.when(\n",
    "      f.size(f.col('posts')) == 0, \n",
    "      missing_field_messages.get('no_posts')),\n",
    "    f.when(\n",
    "      f.col('recommendations_count') == 0, \n",
    "      missing_field_messages.get('no_recommendations')),\n",
    "    f.when(\n",
    "      f.col('about').isNull() & f.col('new_about').isNotNull(), \n",
    "      missing_field_messages.get('no_about') + f.col('new_about')),\n",
    "    f.when(\n",
    "      f.col('about').isNotNull() & f.col('new_about').isNotNull() & f.col('score') < 90, \n",
    "      missing_field_messages.get('suggested_about') + f.col('new_about')),\n",
    "    f.when(\n",
    "      f.col('about_message').isNotNull(), \n",
    "      f.col('about_message')),\n",
    "    f.when(\n",
    "      f.col('position').isNull(),\n",
    "      missing_field_messages.get('no_position')),\n",
    "    f.when(\n",
    "      f.col('followers') < 20,\n",
    "      missing_field_messages.get('low_followers')),\n",
    "    f.when(\n",
    "      f.size(f.col('experience')) == 0, \n",
    "      missing_field_messages.get('no_experience')), \n",
    "    f.when(\n",
    "      f.col('gap_in_experience').isNotNull(), # TODO: adapt to binary or time period\n",
    "      missing_field_messages.get('missing_experience'))\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31fb62a8-cb9f-4367-921c-2827fa84c4fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "optemized_df = predicted_df.select('name', 'id', 'url', 'score_rank', 'score_message', 'suggestions')\n",
    "display(optemized_df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Profile_Pro",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
