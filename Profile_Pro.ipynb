{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18bfc611-a9d3-4544-b843-6315fb84906a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Profile Pro: A LinkedIn Profile Optimizer\n",
    "## Final Project - Data Collection Lab (0940290)\n",
    "### Lihi Kaspi (214676140), Harel Oved (326042389) & Lior Zaphir (326482213)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99768cc0-a0cb-41a7-adaa-80ef43645fee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "import pandas as pd\n",
    "from pyspark.ml.feature import CountVectorizer, Tokenizer, StringIndexer, VectorAssembler, Tokenizer, OneHotEncoder, Word2Vec, HashingTF, IndexToString\n",
    "from pyspark.ml.linalg import SparseVector, Vectors\n",
    "import numpy as np\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.window import Window\n",
    "from datetime import datetime\n",
    "import re\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b928cc60-2d1c-4e5f-b270-3d541c3a15c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Relevant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2757fd63-0941-4d9f-9ea6-846ff83b48b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "profiles = spark.read.parquet('/dbfs/linkedin_people_train_data')\n",
    "# new df with processed vector to go into the model\n",
    "processed_data = spark.read.parquet(\"/Workspace/Users/lihi.kaspi@campus.technion.ac.il/processed_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a6ac684-25f5-447b-bc8c-1e42626c3268",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "processed_data = processed_data.withColumn(\n",
    "    'label', \n",
    "    f.when(f.col('profile_score') < 5, 0\n",
    "    ).when(f.col('profile_score') < 10, 1\n",
    "    ).when(f.col('profile_score') < 15, 2\n",
    "    ).when(f.col('profile_score') < 20, 3\n",
    "    ).otherwise(4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8afcc7df-668f-421a-8237-17a41fc72644",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Good Profiles Score Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71148ed7-d8e4-4a42-a657-626a6c78d63f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a580db1-b485-4702-a48d-0cfe57ec5027",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4350775c-bab9-4218-9c1f-044cb24ea885",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df, test_df = processed_data.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17ac8cf9-ab34-4112-bdf4-878cba1994ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import vector_to_array\n",
    "\n",
    "# Validate the training data\n",
    "train_df = train_df.na.drop()\n",
    "train_df = train_df.filter(f.size(vector_to_array(f.col('features'))) == 133)\n",
    "\n",
    "# Validate the test data\n",
    "test_df = test_df.na.drop()\n",
    "test_df = test_df.filter(f.size(vector_to_array(f.col('features'))) == 133)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "514d7b31-d38a-4d9b-8a2e-2a568c34ac69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "\n",
    "# Define the layers of the neural network\n",
    "# Input layer = number of features, hidden layers = user-defined, output layer = number of classes\n",
    "layers = [133, 64, 32, 5]\n",
    "\n",
    "# Initialize MLP Classifier\n",
    "mlp = MultilayerPerceptronClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\",\n",
    "    maxIter=100,\n",
    "    layers=layers,\n",
    "    blockSize=128,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "mlp_model = mlp.fit(train_df)\n",
    "\n",
    "# Make predictions\n",
    "mlp_predictions = mlp_model.transform(test_df)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = evaluator_accuracy.evaluate(mlp_predictions)\n",
    "f1_score = evaluator_f1.evaluate(mlp_predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1-Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61e0b1b4-aa6d-4d34-a2b8-46e31010610b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_path = 'dbfs:/Workspace/Users/lihi.kaspi@campus.technion.ac.il/mlp_model'\n",
    "if os.path.exists(model_path):\n",
    "    shutil.rmtree(model_path)\n",
    "\n",
    "mlp_model.write().overwrite().save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1352ef53-aa69-48b1-a7a6-d27590481674",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert predictions to pandas DataFrame\n",
    "sample = mlp_predictions.select('prediction').toPandas()\n",
    "\n",
    "# Define the mapping of numeric predictions to category names\n",
    "category_mapping = {0: 'bad', 1: 'below average', 2: 'average', 3: 'above average', 4: 'good'}\n",
    "\n",
    "# Map the numeric predictions to category names\n",
    "sample['category'] = sample['prediction'].map(category_mapping)\n",
    "\n",
    "# Count the occurrences of each category\n",
    "category_counts = sample['category'].value_counts().reindex(category_mapping.values(), fill_value=0)\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(category_counts.index, category_counts.values, edgecolor='black', alpha=0.7, color='#0077B5')\n",
    "plt.title('Histogram of Profile Scores Before Optimization')\n",
    "plt.xlabel('Profile Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef28b933-4f71-4731-a32f-6bf219267eaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Profile Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ab612f1-eee5-42ea-baed-78284e6c9683",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 'about' Section Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a83e58b4-215f-40fe-a79a-0989590d452e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# take: about (if not null), position, job title, reccomendations \n",
    "# --> return: a sentence or two describing the person and job (in a new column called 'new_about')\n",
    "# if all null: return message 'could not generate a short bio -- add more information to your profile' (put null in 'new_about' and add message in a new column called 'about_message')\n",
    "\n",
    "good_profiles_df = ''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4cab94df-d4dd-490d-bb02-680cf93d4f81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_about(input_prompt, model, tokenizer):\n",
    "    # Tokenize the input prompt\n",
    "    inputs = tokenizer(input_prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "    # Generate output text\n",
    "    outputs = model.generate(inputs[\"input_ids\"], max_length=150, num_beams=5, early_stopping=True)\n",
    "\n",
    "    # Decode and return the generated text\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Example usage\n",
    "input_prompt = \"City: New York, Education: Master's in Data Science from Columbia University, Name: Jane Doe, Position: Data Scientist\"\n",
    "about_section = generate_about(input_prompt, model, tokenizer)\n",
    "print(\"Generated About Section:\", about_section)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0db48a2-457c-45be-9c59-118647dca859",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Improvements and Suggetions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "187a0312-7fa5-4b34-9bd9-af75a6f1d18c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "score_messages = {\n",
    "    'excellent score': 'Your profile is excellent, keep it up!',\n",
    "    'high score': 'Your profile is very strong, Check the suggestions to make it excellent',\n",
    "    'medium high score': 'Your profile is good, Try to follow the suggestions to make it even better',\n",
    "    'medium score': 'Your profile could use a few improvements, Try to follow the suggestions to make it even better',\n",
    "    'medium low score': 'Your profile needs to improve, Try to follow the suggestion to make it better',\n",
    "    'low score': 'Your profile is weak, Try to follow the suggestion to make it better',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4eb99eae-46e4-4388-8d33-f7d287775dd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "score_messages = {\n",
    "    100: 'Your profile is excellent, keep it up!', # good profiles with no suggestions\n",
    "    4: 'Your profile is very strong, Check the suggestions to make it excellent',\n",
    "    3: 'Your profile is good, Try to follow the suggestions to make it even better',\n",
    "    2: 'Your profile could use a few improvements, Try to follow the suggestions to make it even better',\n",
    "    1: 'Your profile needs to improve, Try to follow the suggestion to make it better',\n",
    "    0: 'Your profile is weak, Try to follow the suggestion to make it better',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15d4234a-8ae9-4b09-8fc8-a9eafb9a5681",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "missing_field_messages = {\n",
    "    'no_experience': 'Add previous/current comapnies you worked in', \n",
    "    'no_education': 'List your degrees and schools you graduated from',\n",
    "    'no_about': 'Add a short bio about yourself, here is a suggestion: ', # for profiles with no about section at all\n",
    "    'suggested_about': 'Try out this about section: ', # for bad profiles only\n",
    "    'no_company': 'Add the company you currently work in',\n",
    "    'no_languages': 'List all the languages you know and the level of knowledge',\n",
    "    'no_position': 'Add the position you are currently in',\n",
    "    'no_posts': 'Tell your friends about projects you currently work on',\n",
    "    'no_recommendations': 'Ask a colleague to write a few words about you',\n",
    "    'missing_experience': 'There is a gap in your resume, Don\\'t forget to add all of the previous comapnies you worked in', # TODO: cahnge if we do exlicit time periods\n",
    "    'low_followers': 'Ask your colleagues and friends to follow you on LinkedIn!'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82696174-9da2-4377-9508-61ae90a1ce13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# find if there are gaps in the experience array (name new column: 'gap_in_experience')\n",
    "# TODO: Binary or explicit time period? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70f31f75-c24a-4033-83d0-67280a4a84f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "predicted_df = predicted_df.withColumn('suggestions', f.array())\n",
    "\n",
    "predicted_df = predicted_df.withColumn(\n",
    "  'suggestions',\n",
    "  f.array(\n",
    "    f.when(\n",
    "      f.size(f.col('education')) == 0, \n",
    "      missing_field_messages.get('no_education')),\n",
    "    f.when(\n",
    "      f.size(f.col('current_company')) == 0, \n",
    "      missing_field_messages.get('no_company')),\n",
    "    f.when(\n",
    "      f.size(f.col('languages')) == 0, \n",
    "      missing_field_messages.get('no_languages')),\n",
    "    f.when(\n",
    "      f.size(f.col('posts')) == 0, \n",
    "      missing_field_messages.get('no_posts')),\n",
    "    f.when(\n",
    "      f.col('recommendations_count') == 0, \n",
    "      missing_field_messages.get('no_recommendations')),\n",
    "    f.when(\n",
    "      f.col('about').isNull() & f.col('new_about').isNotNull(), \n",
    "      missing_field_messages.get('no_about') + f.col('new_about')),\n",
    "    f.when(\n",
    "      f.col('about').isNotNull() & f.col('new_about').isNotNull() & f.col('score') < 90, \n",
    "      missing_field_messages.get('suggested_about') + f.col('new_about')),\n",
    "    f.when(\n",
    "      f.col('about_message').isNotNull(), \n",
    "      f.col('about_message')),\n",
    "    f.when(\n",
    "      f.col('position').isNull(),\n",
    "      missing_field_messages.get('no_position')),\n",
    "    f.when(\n",
    "      f.col('followers') < 20,\n",
    "      missing_field_messages.get('low_followers')),\n",
    "    f.when(\n",
    "      f.size(f.col('experience')) == 0, \n",
    "      missing_field_messages.get('no_experience')), \n",
    "    f.when(\n",
    "      f.col('gap_in_experience').isNotNull(), # TODO: adapt to binary or time period\n",
    "      missing_field_messages.get('missing_experience'))\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5321e47c-06aa-45f3-a950-fb0521d824e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# placeholder name for the predictions: predicted_df (has all the previous columns + score predictions)\n",
    "\n",
    "predicted_df = predicted_df.withColumn(\n",
    "  'score_rank', \n",
    "  f.when(f.col('prediction') == 4 & f.size(f.col('suggestions')) == 0, 100\n",
    "  ).otherwise(f.col('prediction'))\n",
    ")\n",
    "\n",
    "predicted_df = predicted_df.withColumn(\n",
    "  'score_message',\n",
    "  score_messages.get(f.col('score_rank'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31fb62a8-cb9f-4367-921c-2827fa84c4fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "optemized_df = predicted_df.select('name', 'id', 'url', 'score_rank', 'score_message', 'suggestions')\n",
    "display(optemized_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0603f804-a20e-46cb-8993-170f2a7e101c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Re-Evaluating the Profiles Post Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f0cf0cd-4581-4093-93c0-00e7ea29eb70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# preprocess the profiles with the optimized 'about' sections and let the model predict the new scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "540d27c4-8b96-460f-9b44-eeeddd8baed0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# need to see how listening to suggestions improve score - present the result by increasing number of sugggestions"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Profile_Pro",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
