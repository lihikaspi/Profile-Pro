{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d227fa75-5b1f-451d-a2f7-698c3d84ab96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer, Tokenizer, StringIndexer, VectorAssembler, Tokenizer, OneHotEncoder, Word2Vec, HashingTF, IndexToString\n",
    "from pyspark.ml.linalg import SparseVector, Vectors\n",
    "import numpy as np\n",
    "import sparknlp\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from sparknlp.base import DocumentAssembler, Finisher\n",
    "from sparknlp.annotator import Tokenizer, StopWordsCleaner, WordEmbeddingsModel, SentenceEmbeddings, BertEmbeddings, Word2VecModel\n",
    "from pyspark.ml.feature import VectorAssembler, OneHotEncoder, StringIndexer\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.linalg import VectorUDT, DenseVector\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79860693-9d85-4346-924e-e06fffa089c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "profiles_with_scores = spark.read.parquet(\"/Workspace/Users/lihi.kaspi@campus.technion.ac.il/user_profiles_with_scores.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e254344a-f0ef-43b4-b1de-e1d32cf7dc73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "profiles_with_scores = profiles_with_scores.withColumn(\"about\", f.when(f.col(\"about\").isNull(), \"\").otherwise(f.col(\"about\")))\n",
    "profiles_with_scores = profiles_with_scores.withColumn(\"position\", f.col(\"position\").cast(\"string\"))\n",
    "profiles_with_scores = profiles_with_scores.withColumn(\"position\", f.when(f.col(\"position\").isNull(), \"\").otherwise(f.col(\"position\")))\n",
    "profiles_with_scores = profiles_with_scores.withColumn(\"about_position\", f.concat_ws(\" \", f.col(\"about\"), f.col(\"position\")))\n",
    "profiles_with_scores = profiles_with_scores.withColumn(\"about_position\", f.when(f.col(\"about_position\") == \" \", \"No Info\").otherwise(f.col(\"about_position\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca6cb500-72c7-4607-99c3-755c4fd78a6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "profiles_with_scores = profiles_with_scores.select('id', 'about', 'position', 'education', 'experience', 'languages', 'followers', 'recommendations_count', 'profile_score', 'about_position')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "763a2956-e944-429b-b05e-846b14d5bd8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess `about` using Spark NLP\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"about_position\") \\\n",
    "    .setOutputCol(\"ap_document\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"ap_document\"]) \\\n",
    "    .setOutputCol(\"ap_token\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner() \\\n",
    "    .setInputCols([\"ap_token\"]) \\\n",
    "    .setOutputCol(\"ap_clean_tokens\")\n",
    "\n",
    "embeddings = BertEmbeddings.pretrained(\"small_bert_L2_128\") \\\n",
    "    .setInputCols([\"ap_document\", \"ap_clean_tokens\"]) \\\n",
    "    .setOutputCol(\"ap_embeddings_bert\")\n",
    "\n",
    "sentence_embeddings = SentenceEmbeddings() \\\n",
    "    .setInputCols([\"ap_document\", \"ap_embeddings_bert\"]) \\\n",
    "    .setOutputCol(\"about_position_embeddings\")\n",
    "\n",
    "nlp_pipeline_about = Pipeline(stages=[document_assembler, tokenizer, stopwords_cleaner, embeddings, sentence_embeddings])\n",
    "\n",
    "# Apply NLP Pipeline\n",
    "nlp_model_about = nlp_pipeline_about.fit(profiles_with_scores)\n",
    "processed_data1 = nlp_model_about.transform(profiles_with_scores)\n",
    "display(processed_data1.limit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a439e18-8f82-4e7e-8f97-54da925db755",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Numerical Features\n",
    "processed_data = processed_data1 \\\n",
    "    .withColumn(\"num_education\", f.when(f.size(f.col('education')).isNull(), 0).otherwise(f.size(f.col('education')))) \\\n",
    "    .withColumn(\"num_experience\", f.when(f.size(f.col('experience')).isNull(), 0).otherwise(f.size(f.col('experience')))) \\\n",
    "    .withColumn(\"num_languages\", f.when(f.size(f.col('languages')).isNull(), 0).otherwise(f.size(f.col('languages')))) \\\n",
    "    .withColumn(\"total_followers\", f.when(f.col(\"followers\").isNull(), 0).otherwise(f.col(\"followers\"))) \\\n",
    "    .withColumn(\"num_recommendations\", f.when(f.col(\"recommendations_count\").isNull(), 0).otherwise(f.col(\"recommendations_count\")))\n",
    "\n",
    "display(processed_data.limit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30e732cb-bf01-4516-9048-49fe1f0982dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def to_dense_vector(embeddings_array):\n",
    "    return Vectors.dense(embeddings_array)\n",
    "\n",
    "# Convert to dense vectors\n",
    "to_dense_udf = udf(lambda x: to_dense_vector(x), VectorUDT())\n",
    "\n",
    "processed_data = processed_data.withColumn(\n",
    "    \"about_position_embeddings_dense\", \n",
    "    to_dense_udf(f.expr(\"about_position_embeddings.embeddings[0]\"))\n",
    ")\n",
    "\n",
    "# Assemble features\n",
    "assembler = VectorAssembler(inputCols=[\n",
    "    \"about_position_embeddings_dense\", \"num_education\", \"num_experience\", \"num_languages\",\n",
    "    \"total_followers\", \"num_recommendations\",\n",
    "], outputCol=\"features\")\n",
    "\n",
    "final_data = assembler.transform(processed_data)\n",
    "\n",
    "final_data = final_data.select('id', \"features\", \"profile_score\")\n",
    "\n",
    "display(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8037c4cd-3531-44ff-bf79-959c295eb7fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_data.select('id', 'features', 'profile_score').write.mode(\"overwrite\").parquet(\"/Workspace/Users/lihi.kaspi@campus.technion.ac.il/processed_data.parquet\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Data_Preprocessing",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
