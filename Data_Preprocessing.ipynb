{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d227fa75-5b1f-451d-a2f7-698c3d84ab96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer, Tokenizer, StringIndexer, VectorAssembler, Tokenizer, OneHotEncoder, Word2Vec, HashingTF, IndexToString\n",
    "from pyspark.ml.linalg import SparseVector, Vectors\n",
    "import numpy as np\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from sparknlp.base import DocumentAssembler\n",
    "from sparknlp.annotator import Tokenizer, StopWordsCleaner, WordEmbeddingsModel, SentenceEmbeddings, BertEmbeddings\n",
    "from pyspark.ml.feature import VectorAssembler, OneHotEncoder, StringIndexer\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.linalg import VectorUDT, DenseVector\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79860693-9d85-4346-924e-e06fffa089c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "profiles_with_scores = spark.read.parquet(\"/Workspace/Users/lihi.kaspi@campus.technion.ac.il/user_profiles_with_scores.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e254344a-f0ef-43b4-b1de-e1d32cf7dc73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "profiles_with_scores = profiles_with_scores.withColumn(\"about\", f.when(f.col(\"about\").isNull(), \"No info\").otherwise(f.col(\"about\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7cd735d-8b35-4be9-b2fc-b99d8283be99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(profiles_with_scores.limit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "763a2956-e944-429b-b05e-846b14d5bd8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Preprocess `about` using Spark NLP\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"about\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"clean_tokens\")\n",
    "\n",
    "embeddings = BertEmbeddings.pretrained(\"small_bert_L2_128\") \\\n",
    "    .setInputCols([\"document\", \"clean_tokens\"]) \\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "sentence_embeddings = SentenceEmbeddings() \\\n",
    "    .setInputCols([\"document\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"about_embeddings\")\n",
    "\n",
    "nlp_pipeline = Pipeline(stages=[document_assembler, tokenizer, stopwords_cleaner, embeddings, sentence_embeddings])\n",
    "\n",
    "# Apply NLP Pipeline\n",
    "nlp_model = nlp_pipeline.fit(profiles_with_scores)\n",
    "processed_data = nlp_model.transform(profiles_with_scores)\n",
    "display(processed_data.limit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a439e18-8f82-4e7e-8f97-54da925db755",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. Numerical Features\n",
    "processed_data = processed_data.withColumn(\"num_education\", f.size(f.col(\"education\"))) \\\n",
    "    .withColumn(\"num_experience\", f.size(f.col(\"experience\"))) \\\n",
    "    .withColumn(\"num_languages\", f.size(f.col(\"languages\"))) \\\n",
    "    .withColumn(\"total_followers\", f.col(\"followers\")) \\\n",
    "    .withColumn(\"recommendations\", f.when(f.col(\"recommendations_count\").isNull(), 0).otherwise(f.col(\"recommendations_count\")))\n",
    "\n",
    "display(processed_data.limit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edcb36ce-99d4-4853-9e89-cf73754629cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(processed_data.limit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30e732cb-bf01-4516-9048-49fe1f0982dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def to_dense_vector(embeddings_array):\n",
    "    return Vectors.dense(embeddings_array)\n",
    "\n",
    "# Register a UDF to convert arrays to dense vectors\n",
    "to_dense_udf = udf(lambda x: to_dense_vector(x), VectorUDT())\n",
    "\n",
    "# Apply the UDF to the embeddings column (adjust column name as needed)\n",
    "processed_data = processed_data.withColumn(\n",
    "    \"about_embeddings_dense\", \n",
    "    to_dense_udf(f.expr(\"about_embeddings.embeddings[0]\"))\n",
    ")\n",
    "\n",
    "# Assemble features\n",
    "assembler = VectorAssembler(inputCols=[\n",
    "    \"about_embeddings_dense\", \"num_education\", \"num_experience\", \"num_languages\",\n",
    "    \"total_followers\", \"recommendations\",\n",
    "], outputCol=\"features\")\n",
    "\n",
    "# assembler = VectorAssembler(inputCols=[\n",
    "#     \"about_embeddings_dense\"\n",
    "# ], outputCol=\"features\")\n",
    "\n",
    "final_data = assembler.transform(processed_data)\n",
    "\n",
    "# Select relevant columns\n",
    "final_data = final_data.select('id' , \"features\", \"profile_score\")\n",
    "\n",
    "# Save processed data\n",
    "# final_data.write.parquet(\"processed_profile_data.parquet\")\n",
    "display(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8037c4cd-3531-44ff-bf79-959c295eb7fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# final_data.write.parquet(\"processed_profile_data.parquet\")\n",
    "final_data.select('id', 'features', 'profile_score').write.mode(\"overwrite\").parquet(\"/Workspace/Users/lihi.kaspi@campus.technion.ac.il/processed_data.parquet\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Data_Preprocessing",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
