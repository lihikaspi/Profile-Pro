{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d227fa75-5b1f-451d-a2f7-698c3d84ab96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer, Tokenizer, StringIndexer, VectorAssembler, Tokenizer, OneHotEncoder, Word2Vec, HashingTF, IndexToString\n",
    "from pyspark.ml.linalg import SparseVector, Vectors\n",
    "import numpy as np\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from sparknlp.base import DocumentAssembler\n",
    "from sparknlp.annotator import Tokenizer, StopWordsCleaner, WordEmbeddingsModel, SentenceEmbeddings\n",
    "from pyspark.ml.feature import VectorAssembler, OneHotEncoder, StringIndexer\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.linalg import VectorUDT, DenseVector\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79860693-9d85-4346-924e-e06fffa089c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "profiles_with_scores = spark.read.parquet(\"/Workspace/Users/lihi.kaspi@campus.technion.ac.il/user_profiles_with_scores.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e1a4551-7f4a-4c2b-b2c3-bab4f176a720",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df, test_df = profiles_with_scores.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10fa342c-1cce-4b1f-a55c-73942bd9bbd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sparknlp.pretrained import ResourceDownloader\n",
    "print(ResourceDownloader.showPublicModels(\"word_embedding\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "744c342c-9a18-42a4-92dc-6153c1cf53d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "print(sparknlp.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "763a2956-e944-429b-b05e-846b14d5bd8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Preprocess `about` using Spark NLP\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"about\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"clean_tokens\")\n",
    "\n",
    "embeddings = WordEmbeddingsModel.pretrained() \\\n",
    "    .setInputCols([\"document\", \"clean_tokens\"]) \\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "sentence_embeddings = SentenceEmbeddings() \\\n",
    "    .setInputCols([\"document\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"about_embeddings\")\n",
    "\n",
    "nlp_pipeline = Pipeline(stages=[document_assembler, tokenizer, stopwords_cleaner, embeddings, sentence_embeddings])\n",
    "\n",
    "# Apply NLP Pipeline\n",
    "nlp_model = nlp_pipeline.fit(train_df)\n",
    "processed_data = nlp_model.transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a439e18-8f82-4e7e-8f97-54da925db755",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. Numerical Features\n",
    "processed_data = processed_data.withColumn(\"num_education\", f.size(f.col(\"education\"))) \\\n",
    "    .withColumn(\"num_experience\", f.size(f.col(\"experience\"))) \\\n",
    "    .withColumn(\"num_languages\", f.size(f.col(\"languages\"))) \\\n",
    "    .withColumn(\"total_followers\", f.col(\"followers\")) \\\n",
    "    .withColumn(\"recommendations\", f.col(\"recommendations_count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47f4b1fc-c882-45b5-8767-ffaf3bcdfbb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. Categorical Features - TODO USE THEM???\n",
    "# Index and encode categorical columns\n",
    "# indexer = StringIndexer(inputCol=\"country_code\", outputCol=\"country_code_index\")\n",
    "# encoder = OneHotEncoder(inputCol=\"country_code_index\", outputCol=\"country_code_vec\")\n",
    "# cat_pipeline = Pipeline(stages=[indexer, encoder])\n",
    "\n",
    "# Fit and transform categorical pipeline\n",
    "# cat_model = cat_pipeline.fit(processed_data)\n",
    "# processed_data = cat_model.transform(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "431e8372-ec40-43d5-bf4a-93f10db70c0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4. Assemble features\n",
    "# assembler = VectorAssembler(inputCols=[\n",
    "#     \"about_embeddings\", \"num_education\", \"num_experience\", \"num_languages\",\n",
    "#     \"total_followers\", \"recommendations\", \"country_code_vec\"\n",
    "# ], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e58c4ac8-bde3-43a9-adc7-f0d038641042",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import udf\n",
    "# from pyspark.ml.linalg import VectorUDT, DenseVector\n",
    "# from pyspark.ml.feature import VectorAssembler\n",
    "# import pyspark.sql.functions as f\n",
    "\n",
    "# # UDF to extract embeddings and convert to DenseVector\n",
    "# def extract_embeddings(embeddings):\n",
    "#     return DenseVector(embeddings[0].embeddings) if embeddings else DenseVector([])\n",
    "\n",
    "# extract_embeddings_udf = udf(extract_embeddings, VectorUDT())\n",
    "\n",
    "# # Apply the UDF to extract embeddings\n",
    "# processed_data = processed_data.withColumn(\"about_embeddings_vector\", extract_embeddings_udf(f.col(\"about_embeddings\")))\n",
    "\n",
    "# # Assemble features\n",
    "# assembler = VectorAssembler(\n",
    "#     inputCols=[\n",
    "#         \"about_embeddings_vector\", \"num_education\", \"num_experience\", \"num_languages\",\n",
    "#         \"total_followers\", \"recommendations\"\n",
    "#     ],\n",
    "#     outputCol=\"features\"\n",
    "# )\n",
    "\n",
    "# final_data = assembler.transform(processed_data)\n",
    "\n",
    "# # Select relevant columns\n",
    "# final_data = final_data.select(\"features\", \"filled_precent\")\n",
    "\n",
    "# # Save processed data\n",
    "# # final_data.write.parquet(\"processed_profile_data.parquet\")\n",
    "# display(final_data.limit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30e732cb-bf01-4516-9048-49fe1f0982dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def to_dense_vector(embeddings_array):\n",
    "    return Vectors.dense(embeddings_array)\n",
    "\n",
    "# Register a UDF to convert arrays to dense vectors\n",
    "to_dense_udf = udf(lambda x: to_dense_vector(x), VectorUDT())\n",
    "\n",
    "# Apply the UDF to the embeddings column (adjust column name as needed)\n",
    "processed_data = processed_data.withColumn(\n",
    "    \"about_embeddings_dense\", \n",
    "    to_dense_udf(f.expr(\"about_embeddings.embeddings[0]\"))\n",
    ")\n",
    "\n",
    "\n",
    "# Assemble features\n",
    "assembler = VectorAssembler(inputCols=[\n",
    "    \"about_embeddings_dense\", \"num_education\", \"num_experience\", \"num_languages\",\n",
    "    \"total_followers\", \"recommendations\",\n",
    "], outputCol=\"features\", handleInvalid=\"skip\")\n",
    "\n",
    "final_data = assembler.transform(processed_data)\n",
    "\n",
    "# Select relevant columns\n",
    "final_data = final_data.select(\"features\", \"filled_percent\")\n",
    "\n",
    "# Save processed data\n",
    "# final_data.write.parquet(\"processed_profile_data.parquet\")\n",
    "display(final_data.limit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8037c4cd-3531-44ff-bf79-959c295eb7fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# final_data.write.parquet(\"processed_profile_data.parquet\")\n",
    "final_data.write.mode(\"overwrite\").parquet(\"/Workspace/Users/lihi.kaspi@campus.technion.ac.il/processed_data.parquet\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Data_Preprocessing",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
